{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5a1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import h5py\n",
    "import io\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from utils.general import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71330f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.weight = 'runs/train/exp2/weights/epoch_299.pt'\n",
    "        self.data = 'data/plate.yaml'\n",
    "        self.input_size = 1024\n",
    "        self.device = 'cuda'\n",
    "        self.conf_thres = 0.25\n",
    "        self.iou_thres = 0.65\n",
    "        \n",
    "opt = opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd0e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt.data) as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    classes = data['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25f7cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded runs/train/exp2/weights/epoch_299.pt, epoch 299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (2): Conv(\n",
       "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (4): Conv(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (6): Concat()\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (8): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (9): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (10): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (11): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (12): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (13): Concat()\n",
       "    (14): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (15): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (16): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (17): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (18): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (19): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (20): Concat()\n",
       "    (21): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (22): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (23): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (24): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (25): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (26): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (27): Concat()\n",
       "    (28): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (29): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (30): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (31): SP(\n",
       "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (32): SP(\n",
       "      (m): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (33): SP(\n",
       "      (m): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (34): Concat()\n",
       "    (35): Conv(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (36): Concat()\n",
       "    (37): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (38): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (39): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (40): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (41): Concat()\n",
       "    (42): Conv(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (43): Conv(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (44): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (45): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (46): Concat()\n",
       "    (47): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (48): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (49): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (50): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (51): Concat()\n",
       "    (52): Conv(\n",
       "      (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (53): Conv(\n",
       "      (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (54): Conv(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (55): Conv(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (56): Concat()\n",
       "    (57): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (58): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (59): Concat()\n",
       "    (60): Conv(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (61): Conv(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (62): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (63): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (64): Concat()\n",
       "    (65): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (66): Conv(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (67): Concat()\n",
       "    (68): Conv(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (69): Conv(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (70): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (71): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (72): Concat()\n",
       "    (73): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (74): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (75): Conv(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (76): Conv(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): SyncBatchNorm(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (77): IDetect(\n",
       "      (m): ModuleList(\n",
       "        (0): Conv2d(128, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(256, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(512, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (ia): ModuleList(\n",
       "        (0): ImplicitA()\n",
       "        (1): ImplicitA()\n",
       "        (2): ImplicitA()\n",
       "      )\n",
       "      (im): ModuleList(\n",
       "        (0): ImplicitM()\n",
       "        (1): ImplicitM()\n",
       "        (2): ImplicitM()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(opt.weight)\n",
    "print('Loaded {}, epoch {}'.format(opt.weight, checkpoint['epoch']))\n",
    "model = checkpoint['model'].cuda().half()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97766809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, size):\n",
    "    h, w, c = img.shape\n",
    "    if not (h == size and w == size):\n",
    "        img = img.copy()\n",
    "        scale_x = float(size / w)\n",
    "        scale_y = float(size / h)\n",
    "        ratio = min(scale_x, scale_y)\n",
    "        nw, nh = int(w*ratio), int(h*ratio)\n",
    "        new_img = cv2.resize(img, (nw, nh))\n",
    "\n",
    "        blank = np.zeros((size, size, c))\n",
    "        dw, dh = (size-nw)//2, (size-nh)//2\n",
    "        blank[dh: dh+nh, dw: dw+nw] = new_img\n",
    "        meta = {'nw': nw, 'nh': nh, 'dw': dw, 'dh': dh, 'w': w, 'h': h}\n",
    "        return blank, meta\n",
    "    else:\n",
    "        meta = {}\n",
    "        return img, meta\n",
    "    \n",
    "def preproccess_img(img, device):\n",
    "    img, meta = resize(img, opt.input_size)\n",
    "    img = (img / 255.).astype(np.float32)\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x512x512\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = torch.unsqueeze(img, 0)\n",
    "    img = img.half()\n",
    "    return img, meta\n",
    "\n",
    "def warp_affine(pt, M):\n",
    "    new_pt = np.array([pt[0], pt[1], 1.], dtype=np.float32).T\n",
    "    new_pt = np.dot(M, new_pt)\n",
    "    return new_pt\n",
    "\n",
    "def affine_transform(dets, meta):\n",
    "    '''\n",
    "    Transfer input-sized perdictions to original-sized coordinate.\n",
    "    Input:\n",
    "        dets = [1(batch), num_objs, 6(x1, y1, x2, y2, conf, cls)]\n",
    "        meta = {'nw': resize_w, \n",
    "                'nh': resize_h, \n",
    "                'dw': offset_w, \n",
    "                'dh': offset_h, \n",
    "                'w': original_size_w, \n",
    "                'h': original_size_h}\n",
    "    '''\n",
    "    dets = np.array([x.cpu().numpy() for x in dets[0]])\n",
    "    if len(meta)>0:\n",
    "        p1 = np.float32([[0, 0], [0, meta['nh']], [meta['nw'], 0]])\n",
    "        p2 = np.float32([[0, 0], [0, meta['h']], [meta['w'], 0]])\n",
    "        M = cv2.getAffineTransform(p1, p2)\n",
    "\n",
    "        for i in range(dets.shape[0]):\n",
    "            dets[i, 0] -= meta['dw']\n",
    "            dets[i, 1] -= meta['dh']\n",
    "            dets[i, 2] -= meta['dw']\n",
    "            dets[i, 3] -= meta['dh']\n",
    "\n",
    "            dets[i, 0:2] = warp_affine(dets[i, 0:2], M)\n",
    "            dets[i, 2:4] = warp_affine(dets[i, 2:4], M)\n",
    "        return dets\n",
    "    else:\n",
    "        return dets\n",
    "\n",
    "def transfer_det(dets, num_classes):\n",
    "    '''\n",
    "    Input:\n",
    "        dets = [num_objs, 6(x1, y1, x2, y2, conf, cls)]\n",
    "    '''\n",
    "    top_preds = {}\n",
    "    classes = dets[:, -1]\n",
    "    for j in range(num_classes):\n",
    "        inds = (classes == j)\n",
    "        top_preds[j] = dets[inds, :5].astype(np.float32).tolist()\n",
    "    return top_preds\n",
    "\n",
    "def get_iou(bb1, bb2):\n",
    "    '''\n",
    "    Input:\n",
    "        bb1(groundtruth) = [left_top_x, y, right_bottom_x, y]\n",
    "        bb2(predict_point) = [left_top_x, y, right_bottom_x, y]\n",
    "    '''\n",
    "    x_left = max(bb1[0], bb2[0])\n",
    "    y_top = max(bb1[1], bb2[1])\n",
    "    x_right = min(bb1[2], bb2[2])\n",
    "    y_bottom = min(bb1[3], bb2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n",
    "    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n",
    "\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2d7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bbox(bb1, bb2):\n",
    "    '''\n",
    "    Check if bb2 is completely covered by bb1.\n",
    "    If so, return True, otherwise return False.\n",
    "    Input:\n",
    "        bb1(large region) = [x_min, y_min, x_max, y_max] (all int)\n",
    "        bb2(small region) = [x_min, y_min, x_max, y_max] (all int)\n",
    "    '''\n",
    "    # Assert bb1 is the larger one\n",
    "    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n",
    "    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n",
    "    if bb1_area < bb2_area:\n",
    "        temp = bb2\n",
    "        bb2 = bb1\n",
    "        bb1 = temp\n",
    "    \n",
    "    f1 = bb1[0] <= bb2[0]\n",
    "    f2 = bb1[1] <= bb2[1]\n",
    "    f3 = bb1[2] >= bb2[2]\n",
    "    f4 = bb1[3] >= bb2[3]\n",
    "\n",
    "    if f1 and f2 and f3 and f4:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def group_plate(outp):\n",
    "    '''\n",
    "    Group each character into seperate plates.\n",
    "    Input:\n",
    "        outp = float[[x1, y1, x2, y2, score, class], ...]\n",
    "            i.e. [[     40.859      162.66      142.42      216.09      0.9668          34]\n",
    "                  [     125.08      178.28      138.83      208.91     0.93213           6]\n",
    "                  [         95      176.41      110.94      207.03      0.9248           8]\n",
    "                  [     110.16      177.34      125.16      208.28     0.91211           8]\n",
    "                  [     80.156      175.47      97.344      206.72     0.90674           4]\n",
    "                  [     45.039      173.44      64.414         205     0.89111          13]\n",
    "                  [     60.078      174.06      78.828      205.62     0.81445          17]]\n",
    "    Return: \n",
    "        a sorted list of dict [{'plate': int[x1, y1, x2, y2], 'char':[int[x1, y1, x2, y2, idx], ...]}, ...]\n",
    "             i.e. [{'plate': [40, 162, 142, 216], \n",
    "                    'char':  [[45, 173, 64, 205, 13],\n",
    "                             [60, 174, 78, 205, 17],\n",
    "                             [80, 175, 97, 206, 4],\n",
    "                             [95, 176, 110, 207, 8],\n",
    "                             [110, 177, 125, 208, 8],\n",
    "                             [125, 178, 138, 208, 6]]}]\n",
    "    '''\n",
    "    plates = []\n",
    "    chars = []\n",
    "    groups = []\n",
    "    for obj in outp:\n",
    "        if int(obj[-1]) == 34:\n",
    "            pla = [int(p) for p in obj[:4]]\n",
    "            group = {'plate': pla, 'char':[]}\n",
    "            groups.append(group)\n",
    "        else:\n",
    "            chars.append(obj)\n",
    "    for obj in chars:\n",
    "        cha = [int(obj[0]), int(obj[1]), int(obj[2]), int(obj[3]), int(obj[5])]\n",
    "        for g in groups:\n",
    "            pla = g['plate']\n",
    "            if check_bbox(pla, cha[:4]):\n",
    "                g['char'].append(cha)\n",
    "    ### Sort list\n",
    "    for g in groups:\n",
    "        g['char'] = sorted(g['char'], key=lambda x: x[0])\n",
    "    return groups\n",
    "\n",
    "def get_str(chars):\n",
    "    '''\n",
    "    Create plate string from indivisual detected character.\n",
    "    Input:\n",
    "        chars = a sorted list [int[x1, y1, x2, y2, idx], ...]]\n",
    "    Return:\n",
    "        plate_str = plate string, i.e. 'DH4886'\n",
    "    '''\n",
    "    s = ''\n",
    "    for o in chars:\n",
    "        c = o[-1]\n",
    "        s += classes[c]\n",
    "    return s\n",
    "\n",
    "def get_acc(inp, outp):\n",
    "    \"\"\"\n",
    "    Compute two strings character by character.\n",
    "    Input:\n",
    "        inp: ground truth(str)\n",
    "        outp: detected result(str)\n",
    "    Return:\n",
    "        m: number of groundtruth(int)\n",
    "        count: number of detect correctly(int)\n",
    "    \"\"\"\n",
    "    m = len(inp)\n",
    "    count = sum((Counter(inp) & Counter(outp)).values())\n",
    "    return m, count\n",
    "\n",
    "def compute_acc(outp, labels):\n",
    "    '''\n",
    "    Compute accuracy between detected results and labels.\n",
    "    Input:\n",
    "        outp = a list of dic [{'plate': int[x1, y1, x2, y2], 'char':[int[x1, y1, x2, y2, idx], ...]}, ...]\n",
    "        labels = a list of str, i.e. ['14,71,83,105,FS799', '215,188,324,240,DP4846']\n",
    "    Return:\n",
    "        total = the number of all characters in labels\n",
    "        correct = the number of correct-detected characters\n",
    "    '''\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for label in labels:\n",
    "        line = label.split(',')\n",
    "        plate_gt = [int(x) for x in line[:4]]\n",
    "        for g in outp:\n",
    "            if get_iou(plate_gt, g['plate']) >= 0.5:\n",
    "                detected_plate = get_str(g['char'])\n",
    "                t, c = get_acc(line[-1], detected_plate)\n",
    "                total += t\n",
    "                correct += c\n",
    "    return total, correct\n",
    "\n",
    "def labels_len(labels):\n",
    "    '''\n",
    "    Compute the number of characters in ground truth.\n",
    "    Input:\n",
    "        labels = a list of str, i.e. ['14,71,83,105,FS799', '215,188,324,240,DP4846']\n",
    "    Return:\n",
    "        num = the number of characters of all plates\n",
    "    '''\n",
    "    num = 0\n",
    "    for label in labels:\n",
    "        lines = label.split(',')\n",
    "        n = len(lines[-1])\n",
    "        num += n\n",
    "    return num\n",
    "\n",
    "def get_wer(r, h):\n",
    "    \"\"\"\n",
    "    Compute word_error_rate(WER) of two list of strings.\n",
    "    Input:\n",
    "        r = ground truth\n",
    "        h = predicted results\n",
    "    Return:\n",
    "        result = WER (presented in percentage)\n",
    "        sid = substitution + insertion + deletion\n",
    "        total = the number of groundtruth\n",
    "    \"\"\"\n",
    "    d = np.zeros((len(r) + 1) * (len(h) + 1), dtype=np.uint16)\n",
    "    d = d.reshape((len(r) + 1, len(h) + 1))\n",
    "    for i in range(len(r) + 1):\n",
    "        for j in range(len(h) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    for i in range(1, len(r) + 1):\n",
    "        for j in range(1, len(h) + 1):\n",
    "            if r[i - 1] == h[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    sid = d[len(r)][len(h)]\n",
    "    total = len(r)\n",
    "    result = float(sid) / total * 100\n",
    "\n",
    "    return result, sid, total\n",
    "\n",
    "def transfer_label(lab):\n",
    "    '''\n",
    "    Transfer label(string) into list(int).\n",
    "    Input:\n",
    "        lab: string list ['x_min,y_min,x_max,y_max,plate']\n",
    "            i.e. ['14,71,83,105,FS799', '215,188,324,240,DP4846']\n",
    "    Return:\n",
    "        new_lab: int list [x_min, y_min, x_max, y_max]\n",
    "            i.e. [[14,71,83,105], [215,188,324,240]]\n",
    "    '''\n",
    "    new_lab = []\n",
    "    for l in lab:\n",
    "        _l = l.split(',')\n",
    "        x1 = int(_l[0])\n",
    "        y1 = int(_l[1])\n",
    "        x2 = int(_l[2])\n",
    "        y2 = int(_l[3])\n",
    "        new_lab.append([x1, y1, x2, y2])\n",
    "    \n",
    "    return new_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d48c5",
   "metadata": {},
   "source": [
    "# Test AOLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584c215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create label dictionary.\n",
    "Format: dic = {key: file_name(str), value: [obj1(str), obj2(str), ...]}\n",
    "        obj format = 'x_min, y_min, x_max, y_max, plate'\n",
    "   i.e. dic['train_LE_3'] = ['266,199,350,242,2972KK']\n",
    "        dic['train_LE_33'] = ['14,71,83,105,FS799', '215,188,324,240,DP4846']\n",
    "\"\"\"\n",
    "label_data = {}\n",
    "label_txt = 'E:/MTL_FTP/ChengJungC/dataset/AOLP/label.txt'\n",
    "label_file = open(label_txt, 'r')\n",
    "lines = label_file.readlines()\n",
    "for line in lines:\n",
    "    l = line.strip().split(' ')\n",
    "    name = l[0]\n",
    "    plates = l[1:]\n",
    "    label_data[name] = plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1f4286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2049/2049 [03:06<00:00, 11.02it/s]\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'E:/MTL_FTP/ChengJungC/dataset/AOLP/original/'\n",
    "img_paths = os.listdir(img_dir)\n",
    "img_paths.sort()\n",
    "\n",
    "results = {}\n",
    "for f in tqdm(img_paths, ncols=80):\n",
    "    if f.endswith('.jpg'):\n",
    "        bname = os.path.splitext(f)[0]\n",
    "        img_p = img_dir + f\n",
    "        img = cv2.imread(img_p)\n",
    "        img, meta = preproccess_img(img, opt.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ret = model(img)\n",
    "        output = non_max_suppression(ret[0], conf_thres=opt.conf_thres, iou_thres=opt.iou_thres, labels=[], multi_label=True)\n",
    "        \n",
    "        if len(output[0]) > 0:\n",
    "            output = affine_transform(output, meta)\n",
    "            results[bname] = output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb858e",
   "metadata": {},
   "source": [
    "### Detect plate only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4720fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correctly Detected Plates = 2143\n",
      "Number of Detected Plates = 3547\n",
      "Number of All Plates = 2164\n",
      "Recall = 0.9903\n",
      "Precision = 0.6042\n"
     ]
    }
   ],
   "source": [
    "correct_plate = {}\n",
    "total_p, correct_p, pred_p = 0, 0, 0\n",
    "for k, v in label_data.items():\n",
    "    gt = transfer_label(v)\n",
    "    total_p += len(gt)\n",
    "    if k in results:\n",
    "        r = group_plate(results[k]) # r = [{'plate': int[x1, y1, x2, y2], 'char':[int[x1, y1, x2, y2, label], ...]}, ...]\n",
    "        pred_p += len(r)\n",
    "        correct_r = []\n",
    "        for _r in r:\n",
    "            for idx, bbox in enumerate(gt):\n",
    "                if get_iou(bbox, _r['plate']) >= 0.5:\n",
    "                    n_r = {'plate': _r['plate'], 'char': _r['char'], 'idx': idx}\n",
    "                    correct_r.append(n_r)\n",
    "        num = len(correct_r)\n",
    "        if num > 0:\n",
    "            correct_plate[k] = correct_r\n",
    "            correct_p += num\n",
    "            \n",
    "print(\"Number of Correctly Detected Plates =\", correct_p)\n",
    "print(\"Number of Detected Plates =\", pred_p)\n",
    "print(\"Number of All Plates =\", total_p)\n",
    "print(\"Recall = {:.4f}\".format(correct_p/total_p))\n",
    "print(\"Precision = {:.4f}\".format(correct_p/pred_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc90cdf",
   "metadata": {},
   "source": [
    "### Detect character only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04726cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters in Detected Plates =  12789\n",
      "Error Characters (Detected) = 1572\n",
      "World Error Rate (Detected) = 0.1229\n",
      "\n",
      "Number of Perfectly Recognized Plates =  1175\n",
      "Accuracy(Detected) = 0.5483\n"
     ]
    }
   ],
   "source": [
    "n_perfect = 0  ### number of perfectly recognized plates\n",
    "n_sid = 0  ### number of failed recognized chars in detected\n",
    "n_detected = 0  ### number of chars in detected plates\n",
    "\n",
    "for k, v in label_data.items():\n",
    "    gt_strs = [s.split(',')[-1] for s in v]\n",
    "    if k in correct_plate:\n",
    "        objs = correct_plate[k]\n",
    "        for obj in objs: # obj = [{'plate': int[x1, y1, x2, y2], 'char':[int[x1, y1, x2, y2, label], ...], 'idx': int(i)}]\n",
    "            pred_str = [classes[x[-1]] for x in obj['char']]\n",
    "            wer, sid, t = get_wer(list(gt_strs[obj['idx']]), pred_str)\n",
    "            n_sid += sid\n",
    "            n_detected += t\n",
    "            if wer == 0:\n",
    "                n_perfect += 1\n",
    "\n",
    "\n",
    "print(\"Characters in Detected Plates = \", n_detected)\n",
    "print(\"Error Characters (Detected) =\", n_sid)\n",
    "print(\"World Error Rate (Detected) = {:.4f}\".format(n_sid/n_detected))\n",
    "\n",
    "print(\"\\nNumber of Perfectly Recognized Plates = \", n_perfect)\n",
    "print(\"Accuracy(Detected) = {:.4f}\".format(n_perfect/correct_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ca920",
   "metadata": {},
   "source": [
    "# Test weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f20d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create label dictionary.\n",
    "Format: dic = {key: file_name(str), value: [obj1(str), obj2(str), ...]}\n",
    "        obj format = 'x_min, y_min, x_max, y_max, plate'\n",
    "   i.e. dic['train_LE_3'] = ['266,199,350,242,2972KK']\n",
    "        dic['train_LE_33'] = ['14,71,83,105,FS799', '215,188,324,240,DP4846']\n",
    "\"\"\"\n",
    "label_data = {}\n",
    "label_txt = 'E:/MTL_FTP/ChengJungC/dataset/weather/label.txt'\n",
    "label_file = open(label_txt, 'r')\n",
    "lines = label_file.readlines()\n",
    "for line in lines:\n",
    "    l = line.strip().split(' ')\n",
    "    name = l[0]\n",
    "    plates = l[1:]\n",
    "    label_data[name] = plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b822775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 47/47 [00:04<00:00, 10.15it/s]\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'E:/MTL_FTP/ChengJungC/dataset/weather/original/'\n",
    "img_paths = os.listdir(img_dir)\n",
    "img_paths.sort()\n",
    "\n",
    "results = {}\n",
    "for f in tqdm(img_paths, ncols=80):\n",
    "    if f.endswith('.jpg'):\n",
    "        bname = os.path.splitext(f)[0]\n",
    "        img_p = img_dir + f\n",
    "        img = cv2.imread(img_p)\n",
    "        img, meta = preproccess_img(img, opt.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ret = model(img)\n",
    "        output = non_max_suppression(ret[0], conf_thres=opt.conf_thres, iou_thres=opt.iou_thres, labels=[], multi_label=True)\n",
    "        \n",
    "        if len(output[0]) > 0:\n",
    "            output = affine_transform(output, meta)\n",
    "            results[bname] = output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff548980",
   "metadata": {},
   "source": [
    "### Detect plate only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e133df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correctly Detected Plates = 35\n",
      "Number of Detected Plates = 47\n",
      "Number of All Plates = 54\n",
      "Recall = 0.6481\n",
      "Precision = 0.7447\n"
     ]
    }
   ],
   "source": [
    "correct_plate = {}\n",
    "total_p, correct_p, pred_p = 0, 0, 0\n",
    "for k, v in label_data.items():\n",
    "    gt = transfer_label(v)\n",
    "    total_p += len(gt)\n",
    "    if k in results:\n",
    "        r = group_plate(results[k]) # r = [{'plate': int[x1, y1, x2, y2], 'char':[int[x1, y1, x2, y2, label], ...]}, ...]\n",
    "        pred_p += len(r)\n",
    "        correct_r = []\n",
    "        for _r in r:\n",
    "            for idx, bbox in enumerate(gt):\n",
    "                if get_iou(bbox, _r['plate']) >= 0.5:\n",
    "                    n_r = {'plate': _r['plate'], 'char': _r['char'], 'idx': idx}\n",
    "                    correct_r.append(n_r)\n",
    "        num = len(correct_r)\n",
    "        if num > 0:\n",
    "            correct_plate[k] = correct_r\n",
    "            correct_p += num\n",
    "            \n",
    "print(\"Number of Correctly Detected Plates =\", correct_p)\n",
    "print(\"Number of Detected Plates =\", pred_p)\n",
    "print(\"Number of All Plates =\", total_p)\n",
    "print(\"Recall = {:.4f}\".format(correct_p/total_p))\n",
    "print(\"Precision = {:.4f}\".format(correct_p/pred_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da359923",
   "metadata": {},
   "source": [
    "### Detect character only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075d2d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters in Detected Plates =  220\n",
      "Error Characters (Detected) = 106\n",
      "World Error Rate (Detected) = 0.4818\n",
      "\n",
      "Number of Perfectly Recognized Plates =  4\n",
      "Accuracy(Detected) = 0.1143\n"
     ]
    }
   ],
   "source": [
    "n_perfect = 0  ### number of perfectly recognized plates\n",
    "n_sid = 0  ### number of failed recognized chars in detected\n",
    "n_detected = 0  ### number of chars in detected plates\n",
    "\n",
    "for k, v in label_data.items():\n",
    "    gt_strs = [s.split(',')[-1] for s in v]\n",
    "    if k in correct_plate:\n",
    "        objs = correct_plate[k]\n",
    "        for obj in objs: # obj = [{'plate': int[x1, y1, x2, y2], 'char':[int[x1, y1, x2, y2, label], ...], 'idx': int(i)}]\n",
    "            pred_str = [classes[x[-1]] for x in obj['char']]\n",
    "            wer, sid, t = get_wer(list(gt_strs[obj['idx']]), pred_str)\n",
    "            n_sid += sid\n",
    "            n_detected += t\n",
    "            if wer == 0:\n",
    "                n_perfect += 1\n",
    "\n",
    "\n",
    "print(\"Characters in Detected Plates = \", n_detected)\n",
    "print(\"Error Characters (Detected) =\", n_sid)\n",
    "print(\"World Error Rate (Detected) = {:.4f}\".format(n_sid/n_detected))\n",
    "\n",
    "print(\"\\nNumber of Perfectly Recognized Plates = \", n_perfect)\n",
    "print(\"Accuracy(Detected) = {:.4f}\".format(n_perfect/correct_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce062c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
